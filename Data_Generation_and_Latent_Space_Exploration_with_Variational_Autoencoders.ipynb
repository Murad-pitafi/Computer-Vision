{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPtFJqJ4PwXyzi3g3RJyW82",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Murad-pitafi/Computer-Vision/blob/main/Data_Generation_and_Latent_Space_Exploration_with_Variational_Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTgYAOwuc2ZH",
        "outputId": "2b19bdfe-22c6-47d6-b7d7-b07e556e31bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.10MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 133kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.09MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.24MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_dim=2):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 400), nn.ReLU(), nn.Linear(400, 128), nn.ReLU())\n",
        "        self.mu_layer = nn.Linear(128, latent_dim)\n",
        "        self.logvar_layer = nn.Linear(128, latent_dim)\n",
        "        self.decoder = nn.Sequential(nn.Linear(latent_dim, 128), nn.ReLU(), nn.Linear(128, 400), nn.ReLU(), nn.Linear(400, 28 * 28), nn.Sigmoid())\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = self.mu_layer(h), self.logvar_layer(h)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x.view(-1, 28 * 28))\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n"
      ],
      "metadata": {
        "id": "DSq44TmSdF4b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae = VAE()\n",
        "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
        "\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    recon_loss = nn.functional.binary_cross_entropy(recon_x, x.view(-1, 28 * 28), reduction='sum')\n",
        "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + kld\n"
      ],
      "metadata": {
        "id": "ARYwZKG1d6oQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    vae.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = Variable(data)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = vae(data)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}, Loss: {train_loss/len(train_loader.dataset):.4f}')\n"
      ],
      "metadata": {
        "id": "2Jpvegr1ePKN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_reconstructions():\n",
        "    vae.eval()\n",
        "    data, _ = next(iter(train_loader))\n",
        "    data = data[:8]\n",
        "    recon, _, _ = vae(Variable(data))\n",
        "    fig, axes = plt.subplots(2, 8, figsize=(15, 4))\n",
        "    for i in range(8):\n",
        "        axes[0, i].imshow(data[i].view(28, 28).detach().numpy(), cmap='gray')\n",
        "        axes[1, i].imshow(recon[i].view(28, 28).detach().numpy(), cmap='gray')\n",
        "        axes[0, i].axis('off')\n",
        "        axes[1, i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "visualize_reconstructions()\n"
      ],
      "metadata": {
        "id": "Z1Z-Ozc_eQwv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_samples = torch.randn(16, 2)\n",
        "generated_images = vae.decode(z_samples).detach()\n",
        "fig, axes = plt.subplots(1, 16, figsize=(15, 4))\n",
        "for i, img in enumerate(generated_images):\n",
        "    axes[i].imshow(img.view(28, 28).numpy(), cmap='gray')\n",
        "    axes[i].axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-99PqUcTfNb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "z1 = np.linspace(-3, 3, 10)\n",
        "z2 = np.linspace(-3, 3, 10)\n",
        "fig, axes = plt.subplots(10, 10, figsize=(10, 10))\n",
        "for i, z1_val in enumerate(z1):\n",
        "    for j, z2_val in enumerate(z2):\n",
        "        z = torch.FloatTensor([[z1_val, z2_val]])\n",
        "        generated_img = vae.decode(z).detach()\n",
        "        axes[i, j].imshow(generated_img.view(28, 28).numpy(), cmap='gray')\n",
        "        axes[i, j].axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mY-nbu0wfRWJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}